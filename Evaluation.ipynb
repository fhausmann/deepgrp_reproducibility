{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union, Dict, Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = './results'\n",
    "REPEATS_TO_SEARCH = [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "cimport cython\n",
    "cimport numpy as np\n",
    "@cython.boundscheck(False)  # Deactivate bounds checking\n",
    "@cython.wraparound(False)   # Deactivate negative indexing.\n",
    "def confusion_matrix(np.int8_t[:] true_class, np.int8_t[:] pred_class, long[:,:] output, long length):\n",
    "    \"\"\" calculate confusion matrix\"\"\"\n",
    "    cdef int i\n",
    "    for i in range(length):\n",
    "        output[true_class[i],pred_class[i]]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_Y(filename: str, chromosom: str, length: int,\n",
    "                 repeats_to_search: List[int]) -> np.array:\n",
    "    \"\"\" Reads parse_rm file of repeats to numpy array\"\"\"\n",
    "\n",
    "    Ydata = pd.read_csv(filename, sep='\\s+', header=None, index_col=False, usecols=[0,1,2,3])\n",
    "    Ydata.columns = [\n",
    "        'chromosom', 'begin', 'end', 'repeatnumber'\n",
    "    ]\n",
    "    Ydata = Ydata[Ydata.chromosom == chromosom]\n",
    "    Ydata.drop('chromosom', axis=1, inplace=True)\n",
    "\n",
    "    bool_series = None\n",
    "    for number in repeats_to_search:\n",
    "        if bool_series is None:\n",
    "            bool_series = (Ydata['repeatnumber'] == number)\n",
    "        else:\n",
    "            bool_series |= (Ydata['repeatnumber'] == number)\n",
    "    Ydata = Ydata[bool_series]\n",
    "    Y = np.zeros((len(repeats_to_search) + 1, length), dtype=np.int8)\n",
    "\n",
    "    def assign_toY(row):\n",
    "        Y[row['repeatnumber'], row.begin:row.end] = 1\n",
    "\n",
    "    Ydata.apply(assign_toY, axis=1)\n",
    "    return Y.argmax(axis=0).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_array(filename: str,\n",
    "                  shape: np.array,\n",
    "                  dnabrnn: bool = False) -> np.array:\n",
    "    \"\"\"Reads dna-brnn or deepgrp file to array\"\"\"\n",
    "    headernames = [\"file\", \"chr\", \"start\", \"end\", \"class\"]\n",
    "    if dnabrnn:\n",
    "        headernames.pop(0)\n",
    "    tmp = pd.read_csv(filename, header=None, sep=\"\\t\",\n",
    "                      names=headernames).filter(headernames[-3:], axis=1)\n",
    "    Y = np.zeros(shape, dtype=np.int8)\n",
    "\n",
    "    def assign_toY(row):\n",
    "        Y[row.start:row.end] = row['class']\n",
    "\n",
    "    tmp.apply(assign_toY, axis=1)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcc(C):\n",
    "    \"\"\" MCC implementation based on sklearn\"\"\"\n",
    "    t_sum = C.sum(axis=1, dtype=np.float64)\n",
    "    p_sum = C.sum(axis=0, dtype=np.float64)\n",
    "    n_correct = np.trace(C, dtype=np.float64)\n",
    "    n_samples = p_sum.sum()\n",
    "    cov_ytyp = n_correct * n_samples - np.dot(t_sum, p_sum)\n",
    "    cov_ypyp = n_samples**2 - np.dot(p_sum, p_sum)\n",
    "    cov_ytyt = n_samples**2 - np.dot(t_sum, t_sum)\n",
    "    return cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(predictions_class: np.array, true_class: np.array):\n",
    "    \"\"\"Calculated important metrics.\"\"\"\n",
    "    nof_labels = len(REPEATS_TO_SEARCH) + 1\n",
    "    cnf_matrix = np.zeros((nof_labels, nof_labels), dtype=int)\n",
    "    confusion_matrix(true_class, predictions_class, cnf_matrix,\n",
    "                     true_class.shape[0])\n",
    "    true_positive = np.diag(cnf_matrix).astype(float)\n",
    "    false_positive = (cnf_matrix.sum(axis=0) - true_positive).astype(float)\n",
    "    false_negative = (cnf_matrix.sum(axis=1) - true_positive).astype(float)\n",
    "    true_negative = (\n",
    "        cnf_matrix.sum() -\n",
    "        (false_positive + false_negative + true_positive)).astype(float)\n",
    "    metrics = {}\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    metrics[\"TPR\"] = true_positive / (true_positive + false_negative)\n",
    "    # Specificity or true negative rate\n",
    "    metrics[\"TNR\"] = true_negative / (true_negative + false_positive)\n",
    "    # Precision or positive predictive value\n",
    "    metrics[\"PPV\"] = true_positive / (true_positive + false_positive)\n",
    "    # Negative predictive value\n",
    "    metrics[\"NPV\"] = true_negative / (true_negative + false_negative)\n",
    "    # Fall out or false positive rate\n",
    "    metrics[\"FPR\"] = false_positive / (false_positive + true_negative)\n",
    "    # False negative rate\n",
    "    metrics[\"FNR\"] = false_negative / (true_positive + false_negative)\n",
    "    # False discovery rate\n",
    "    metrics[\"FDR\"] = false_positive / (true_positive + false_positive)\n",
    "    # Accuracy\n",
    "    metrics[\"ACC\"] = (true_positive + true_negative) / \\\n",
    "        (true_positive + false_positive + false_negative + true_negative)\n",
    "    # F1 -Score\n",
    "    metrics[\"F1\"] = 2 * metrics[\"TPR\"] * \\\n",
    "        metrics[\"PPV\"] / (metrics[\"TPR\"] + metrics[\"PPV\"])\n",
    "    metrics[\"TotalACC\"] = (\n",
    "        true_class == predictions_class).sum() / true_class.shape[0]\n",
    "    metrics['MCC'] = ((true_positive * true_negative) -\n",
    "                      (false_positive * false_negative)) / np.sqrt(\n",
    "                          (true_positive + false_positive) *\n",
    "                          (true_positive + false_negative) *\n",
    "                          (true_negative + false_positive) *\n",
    "                          (true_negative + false_negative))\n",
    "    metrics['totalMCC'] = mcc(cnf_matrix)\n",
    "    for key in metrics:\n",
    "        if isinstance(metrics[key], np.ndarray):\n",
    "            metrics[key] = metrics[key].tolist()\n",
    "    metrics['confusionmatrix'] = cnf_matrix.tolist()\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_all(results, chr_length, references, outputs,  is_dnabrnn=False):\n",
    "    \"\"\" Calculates metrics based on deepgrp or dna-brnn output file\"\"\"\n",
    "    for k in results:\n",
    "        foldername, chrfile = os.path.split(k)\n",
    "        chromosom = chrfile.replace('.fa', '').replace(\"telomere_to_telomere_X\", \"CM020874.1\")\n",
    "        seqlen = int(chr_length.loc[(foldername,chromosom)])\n",
    "        for name, reference in references[foldername].items():\n",
    "            outputs.setdefault(name, {})\n",
    "            outputs[name].setdefault(chromosom, {})\n",
    "            if outputs[name][chromosom].keys() == results[k].keys():\n",
    "                continue\n",
    "            if isinstance(reference, str):\n",
    "                Ytrue = preprocess_Y(reference, chromosom, seqlen, REPEATS_TO_SEARCH)\n",
    "            else:\n",
    "                Ytrue_diff = preprocess_Y(reference[0], chromosom, seqlen, REPEATS_TO_SEARCH)\n",
    "                Ytrue = preprocess_Y(reference[1], chromosom, seqlen, REPEATS_TO_SEARCH)\n",
    "                Ytrue[Ytrue == Ytrue_diff] = 0\n",
    "            for model in results[k]:\n",
    "                if model in outputs[name][chromosom]:\n",
    "                    continue\n",
    "                predfilename = \"{}_{}.fa_{}.tsv\".format(foldername, chromosom,\n",
    "                                                        model)\n",
    "                predfilename = predfilename.replace(\"_CM020874.1\",\"telomere_to_telomere_X\")\n",
    "                Ypred = file_to_array(predfilename, Ytrue.shape, is_dnabrnn)\n",
    "                metrics = calculate_metrics(Ypred, Ytrue)\n",
    "                outputs[name][chromosom][model] = metrics\n",
    "                del Ypred\n",
    "            del Ytrue\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr_length = pd.DataFrame()\n",
    "for chromosome in pathlib.Path(\"data\").glob(\"*.chrom.sizes\"):\n",
    "    tmp = pd.read_csv(\n",
    "    chromosome,\n",
    "    sep='\\t',\n",
    "    header=None,\n",
    "    names=['chromosome', 'sequence length'])\n",
    "    tmp[\"genomebuild\"] = chromosome.stem\n",
    "    chr_length = chr_length.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFERENCE = {\n",
    "    \"hg19\": {\"hg19\":\"repeatmasker/repeats_hg19.tsv\"},\n",
    "    \"hg38\": {\"hg38\":\"repeatmasker/repeats_hg38.tsv\",\n",
    "             \"dfam\":\"dfam/hg38.dfam.bed\",\n",
    "             #\"dfam_and_rm\":\"dfam_repeatmasker_intersection.csv\",\n",
    "            #\"dfam_no_rm\":\"dfam_not_repeatmasker.csv\",\n",
    "             #\"hg19_hg38_similar\":\"repeatmaskerhg38_nonexacthg19_intersection.tsv\",\n",
    "            },\n",
    "    \"mm10\": {\"mm10\": \"mm10.bed\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Evaluate DeepGRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'deepgrp_results.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with pathlib.Path(RESULTS_PATH, \"deepgrp_runningtime.json\").open('r') as file:\n",
    "        results = json.load(file)\n",
    "except (json.JSONDecodeError, FileNotFoundError):\n",
    "    results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with pathlib.Path(RESULTS_PATH,filename).open('r') as file:\n",
    "        outputs = json.load(file)\n",
    "except (json.JSONDecodeError, FileNotFoundError):\n",
    "    outputs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "deepgrp_results = calculate_all(results, chr_length, REFERENCE,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pathlib.Path(RESULTS_PATH, filename).open('w') as file:\n",
    "    json.dump(deepgrp_results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Evaluate dna-brnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'dnabrnn_results.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with pathlib.Path(RESULTS_PATH, \"dnabrnn_runningtime.json\").open('r') as file:\n",
    "        results = json.load(file)\n",
    "except (json.JSONDecodeError, FileNotFoundError):\n",
    "    results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with pathlib.Path(RESULTS_PATH,filename).open('r') as file:\n",
    "        outputs = json.load(file)\n",
    "except (json.JSONDecodeError, FileNotFoundError):\n",
    "    outputs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnabrnnresults = calculate_all(results, chr_length, REFERENCE,outputs, is_dnabrnn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(filename), 'w') as file:\n",
    "    json.dump(dnabrnnresults, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:hydrogen"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
